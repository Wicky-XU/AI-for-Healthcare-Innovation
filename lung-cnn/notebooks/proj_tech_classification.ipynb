{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# CNN-based Lung CT Images Classification\n",
    "## Import packages\n",
    "Please make sure you have all the required packages installed. If GPU is available, but you want to use CPU to train your model, make sure you add \" os.environ['CUDA_VISIBLE_DEVICES'] = '-1' \" before \"from keras.preprocessing.image import ImageDataGenerator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import shutil\n",
    "import tensorflow\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation (this step has been done for you)\n",
    "\n",
    "Images in the original dataset are usually in different sizes, so we need to resize and normalise them to fit the CNN model. Depending on the images you choose to use for training your model, some other preprocessing methods (cropping, zooming, etc.) may be required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split your dataset into training and validation\n",
    "Validation dataset would not be used to train your network, it is normally for evaluating your model performance and choosing the best set of hyperparameters. Choose the size of your training and validation set yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment if using linux/macos\n",
    "#!rm -rf Train_covid Val_covid\n",
    "#!mkdir Train_covid Val_covid Train_covid/yes Train_covid/no Val_covid/yes Val_covid/no\n",
    "\n",
    "#uncomment if using windows\n",
    "!rmdir Train_covid Val_covid /s /q\n",
    "!md Train_covid Val_covid Train_covid\\yes Train_covid\\no Val_covid\\yes Val_covid\\no\n",
    "\n",
    "\n",
    "\n",
    "IMG_PATH = 'covid19/'\n",
    "for CLASS in os.listdir(IMG_PATH):\n",
    "    if not CLASS.startswith('.'):\n",
    "        files = os.listdir(IMG_PATH + CLASS)\n",
    "        random.shuffle(files)\n",
    "        IMG_NUM = len(files)\n",
    "        for (n, FILE_NAME) in enumerate(files):\n",
    "            img = IMG_PATH + CLASS + '/' + FILE_NAME\n",
    "            # 80% of images will be used for training, change the number here \n",
    "            # to use different number of images for training your model.\n",
    "            if n < 0.8*IMG_NUM:\n",
    "                shutil.copy(img, 'Train_covid/'+ CLASS + '/' + FILE_NAME)\n",
    "            else:\n",
    "                shutil.copy(img, 'Val_covid/'+ CLASS + '/' + FILE_NAME)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot images\n",
    "Plot some sample images here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(img_path,n=20):\n",
    "    files_list = []\n",
    "    labels_list = []\n",
    "    for path, subdirs, files in os.walk(img_path):\n",
    "        for name in files:\n",
    "            files_list.append(os.path.join(path, name))\n",
    "            labels_list.append(path.split('/')[1])\n",
    "    imgs_lbls = list(zip(files_list, labels_list))\n",
    "    random.shuffle(imgs_lbls)\n",
    "    files_list, labels_list = zip(*imgs_lbls)\n",
    "    j = 5\n",
    "    i = int(n/j)\n",
    "    plt.figure(figsize=(15,10))\n",
    "    k = 1\n",
    "    for file, lbl in zip(files_list[:n], labels_list[:n]):\n",
    "        img = cv2.imread(file)\n",
    "        plt.subplot(i,j,k)\n",
    "        plt.imshow(img)\n",
    "        plt.xlabel(lbl)\n",
    "        k += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_samples(IMG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-time data augmentation\n",
    "Generalizability is crucial to a deep learning model and it refers to the performance difference of a model when evaluated on the seen data (training data) versus the unseen data (testing data). Improving the generalizability of these models has always been a difficult challenge. \n",
    "\n",
    "<img src=\"files/img.jpg\">\n",
    "\n",
    "\n",
    "**Data Augmentation** is an effective way of improving the generalizability, because the augmented data will represent a more comprehensive set of possible data samples and minimizing the distance between the training and validation/testing sets.\n",
    "\n",
    "There are many data augmentation methods you can choose in this projects including rotation, shifting, flipping, etc.\n",
    "\n",
    "You are encouraged to try different augmentation method to get the best classification accuracy.\n",
    "\n",
    "**Question**\n",
    "\n",
    "Applying data augmentation to medical images may sometimes make the images uninterpretable to human. For instance, a heart may not look like a heart after shearing the image. Would training the model with these uninterpretable images helpful to improving the model performance? Why do you think it is helpful/not helpful?\n",
    "\n",
    "## Get the data generator ready\n",
    "\n",
    "You may change the batch size of your training data here. A large batch size or even a batch size that equals to the entire dataset is more likely to get your model to the convergence to the global optima of the loss function, but this is at the cost of computational efficiency and sometimes large batch size would lead to a bad model generalisation. \n",
    "\n",
    "There is always a trade-off between large and small batch size. Choose a reasonable batch size here to get the best model performance.\n",
    "\n",
    "You can add your data augmentation methods here. Some simple example can be found at https://towardsdatascience.com/image-augmentation-using-python-numpy-opencv-and-skimage-ef027e9898da."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'Train_covid/'\n",
    "VAL_DIR = 'Val_covid/'\n",
    "IMG_SIZE = (224,224)\n",
    "RANDOM_SEED = 100\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    #add your augmentation methods here\n",
    "    #rotation_range=15,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    color_mode='rgb',\n",
    "    target_size=IMG_SIZE,\n",
    "    interpolation='bicubic',\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    color_mode='rgb',\n",
    "    target_size=IMG_SIZE,\n",
    "    interpolation='bicubic',\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    seed=RANDOM_SEED\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the backbone model\n",
    "\n",
    "To extract the features from the dataset, a backbone network is used here. Initially, VGG16 is used here as an example.\n",
    "\n",
    "To achieve the best classification accuracy, you are encouraged to try different models. A list of models you can try is given at https://keras.io/api/applications/. Remember to update the **Preparing your environment** and **this** part to use a different backbone model, for instance, to use the ResNet50 as the backbone network, change 'from keras.applications.vgg16 import VGG16, preprocess_input' into 'from keras.applications.resnet_v2 import ResNet50, preprocess_input'\n",
    "\n",
    "These models are pretrained on ImageNet dataset for classification task and you can choose to finetune the pretrained network (transfer learning: https://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf) or train it from the scratch for the lung image classification task.\n",
    "\n",
    "VGG16: https://arxiv.org/pdf/1409.1556\n",
    "\n",
    "ResNet: https://arxiv.org/abs/1512.03385\n",
    "\n",
    "DenseNet: https://arxiv.org/abs/1608.06993\n",
    "\n",
    "**Question**\n",
    "\n",
    "What are the advantages and disadvantages of finetuning a model for lung image classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(\n",
    "    #uncomment if you want to train your network from scratch.\n",
    "    #weight = None\n",
    "    include_top=False, \n",
    "    input_shape=IMG_SIZE + (3,)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model for lung image classification\n",
    "\n",
    "A classifier is added to the backbone network here. The loss function used to train the model is binary cross entropy (details can be found at https://keras.io/api/losses/probabilistic_losses/#binarycrossentropy-class and https://machinelearningmastery.com/cross-entropy-for-machine-learning/). \n",
    "\n",
    "The optimizer used here is ADAM (https://arxiv.org/abs/1412.6980) and you can leave it unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "\n",
    "# uncomment here if you want to finetune the top layer(classifier) of a pretrained network only. \n",
    "# model.layers[0].trainable = False\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=Adam(lr=1e-4),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "The early stopping would stop the training process when a pre-defined metric stops improving. More details can be found at https://keras.io/api/callbacks/early_stopping/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "earlystopping = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    mode='max',\n",
    "    patience=20\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[earlystopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training result##\n",
    "\n",
    "**Question**\n",
    "\n",
    "What causes the gap between training accuracy/loss and test accuracy/loss? How do you reduce the gap between training accuracy/loss and test accuracy/loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(1, len(history.epoch) + 1)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Train Set')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Set')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Train Set')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Set')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your trained model\n",
    "If you feel your model has been trained to convergence, save it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('trained_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "Test your trained model on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_path, img_size=IMG_SIZE):\n",
    "    X = []\n",
    "    y = []\n",
    "    i = 0\n",
    "    for path in tqdm(sorted(os.listdir(dir_path))):\n",
    "        if not path.startswith('.'):\n",
    "            for file in os.listdir(dir_path + path):\n",
    "                if not file.startswith('.'):\n",
    "                    img = cv2.imread(dir_path + path + '/' + file)\n",
    "                    img = cv2.resize(img, dsize=img_size, interpolation=cv2.INTER_CUBIC)\n",
    "                    X.append(preprocess_input(img))\n",
    "                    y.append(i)\n",
    "            i += 1\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    print(f'{len(X)} images loaded from {dir_path} directory.')\n",
    "    return X, y\n",
    "\n",
    "X_val, y_val = load_data(VAL_DIR)\n",
    "predictions = model.predict(X_val)\n",
    "print(predictions)\n",
    "predictions = [1 if x>0.5 else 0 for x in predictions]\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "print('Val Accuracy = %.2f' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
